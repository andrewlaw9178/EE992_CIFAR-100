{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FUxPesQh3j12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FUxPesQh3j12",
    "outputId": "4598d0fb-8465-4328-f0d1-7326db98a9fb"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ll6Dvqkk3lYe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ll6Dvqkk3lYe",
    "outputId": "8f1bc894-866d-4b92-fd87-d969539b0f95"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4789b266-7879-4d97-a26b-da3cb5a78005",
   "metadata": {
    "id": "4789b266-7879-4d97-a26b-da3cb5a78005"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb342dd-fd78-418b-a94f-82f5361a1ae9",
   "metadata": {
    "id": "5cb342dd-fd78-418b-a94f-82f5361a1ae9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf # Access to models, datasets and training\n",
    "from tensorflow.keras.datasets import cifar100 # Access to CIFAR-100\n",
    "from tensorflow.keras.applications import ResNet50 # Access to pre-trained model\n",
    "from tensorflow.keras import layers, models, optimizers # Access to building blocks of a model\n",
    "from tensorflow.keras.models import load_model # Ability to load best_saved model\n",
    "from tensorflow import keras # Access to stuff for model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
    "from sklearn.model_selection import train_test_split # To help split dataset up\n",
    "from sklearn.metrics import confusion_matrix, classification_report # Analysis of model train, val & test\n",
    "import numpy as np # Manipulate data\n",
    "import pandas as pd # Statistical analysis of data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt # Plot data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe864ae-fdc9-4938-ba96-47e5f477d04e",
   "metadata": {
    "id": "bbe864ae-fdc9-4938-ba96-47e5f477d04e"
   },
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58c2d0c-f7b4-4b60-b914-de157ece028a",
   "metadata": {
    "id": "e58c2d0c-f7b4-4b60-b914-de157ece028a"
   },
   "outputs": [],
   "source": [
    "def display_imgs(imgs, labels):\n",
    "        plt.subplots(figsize=(10,10))\n",
    "        for i in range(16):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            k = np.random.randint(0, imgs.shape[0])\n",
    "            if i == 0:\n",
    "                print(f\"labels[{k}].shape: {labels[k].shape}\")\n",
    "                print(f\"imgs[{k}].shape: {imgs[k].shape}\")\n",
    "            plt.imshow(imgs[k])\n",
    "            #plt.title(labels[k])\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def class_distrib(y, labels_names, dataset_name):\n",
    "        counts = pd.DataFrame(data=y).value_counts().sort_index()\n",
    "        #print(f\"counts:\\n{counts}\")\n",
    "        fig, ax = plt.subplots(figsize=(20,10))\n",
    "        ax.bar(labels_names, counts)\n",
    "        ax.set_xticklabels(labels_names, rotation=90, fontsize=15)\n",
    "        plt.title(f\"Distribution of '{dataset_name}' Dataset\", fontsize=25)\n",
    "        plt.grid()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def augment_dataset(x, y):\n",
    "        x = tf.image.resize(x, (224, 224))  # Resize images\n",
    "        x = tf.image.random_flip_left_right(x)  # Random horizontal flip\n",
    "        x = tf.image.random_brightness(x, max_delta=0.2)  # Adjust brightness\n",
    "        x = tf.image.random_contrast(x, lower=0.8, upper=1.2)  # Adjust contrast\n",
    "        y = tf.squeeze(tf.one_hot(y, depth=100, dtype=tf.float32))  # One-hot encode labels\n",
    "        return x, y\n",
    "\n",
    "def plot_evidence(epochs, train_loss, val_loss, train_acc, val_acc):\n",
    "        # Plot Training and Validation Loss\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, train_loss, label='Training Loss')\n",
    "        plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "\n",
    "        # Plot Training and Validation Accuracy\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, train_acc, label='Training Accuracy')\n",
    "        plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f041d957-e917-42b8-829b-cc0280e0dc45",
   "metadata": {
    "id": "f041d957-e917-42b8-829b-cc0280e0dc45"
   },
   "source": [
    "# Dropout(0.6), weight_decay(3e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8709554-885e-488b-85c8-81eaff378b09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "c8709554-885e-488b-85c8-81eaff378b09",
    "outputId": "105ebcea-c800-4edd-8cf6-f4a66e86e697",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for repeat_2_times in range(2):\n",
    "    #### <<<<<<<<<<Load and process data>>>>>>>>>>\n",
    "    # Load CIFAR-100 dataset\n",
    "    (X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "\n",
    "    # Split (8000) of training data into temporary set\n",
    "    X_temp, X_train, y_temp, y_train = train_test_split(X_train, y_train, test_size=0.84, stratify=y_train, random_state=42)\n",
    "    print(f\"X_temp.shape: {X_temp.shape}\\n\")\n",
    "\n",
    "    # Split temp data into equal validation (4000) and testing (4000) data\n",
    "    X_temp_val, X_temp_test, y_temp_val, y_temp_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "    print(f\"X_temp_val.shape: {X_temp_val.shape}\")\n",
    "    print(f\"y_temp_val.shape: {y_temp_val.shape}\")\n",
    "    print(f\"X_temp_test.shape: {X_temp_test.shape}\")\n",
    "    print(f\"y_temp_test.shape: {y_temp_test.shape}\\n\")\n",
    "\n",
    "    # Split test data into validation (5000) and testing (5000)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=42)\n",
    "\n",
    "    # Add temp_val to validation (9000) and temp_test to testing (9000) to get a 70/15/15 data split\n",
    "    X_val = np.concatenate((X_val, X_temp_val), axis=0)\n",
    "    y_val = np.concatenate((y_val, y_temp_val), axis=0)\n",
    "    X_test = np.concatenate((X_test, X_temp_test), axis=0)\n",
    "    y_test = np.concatenate((y_test, y_temp_test), axis=0)\n",
    "\n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"y_train.shape: {y_train.shape}\")\n",
    "    print(f\"X_val.shape: {X_val.shape}\")\n",
    "    print(f\"y_val.shape: {y_val.shape}\")\n",
    "    print(f\"X_test.shape: {X_test.shape}\")\n",
    "    print(f\"y_test.shape: {y_test.shape}\\n\")\n",
    "\n",
    "    display_imgs(X_train, y_train)\n",
    "\n",
    "    # Normalise images (scale to range [0, 1]) - Improves convergence speed & accuracy\n",
    "    X_train, X_val, X_test = X_train / 255.0, X_val / 255.0, X_test / 255.0\n",
    "    display_imgs(X_train, y_train)\n",
    "\n",
    "    labels_names = ['beaver','dolphin','otter','seal','whale','aquarium fish','flatfish','ray','shark','trout',\n",
    "                   'orchids','poppies','roses','sunflowers','tulips','bottles','bowls','cans','cups','plates',\n",
    "                   'apples','mushrooms','oranges','pears','sweet peppers','clock','computer keyboard','lamp',\n",
    "                   'telephone','television','bed','chair','couch','table','wardrobe','bee','beetle','butterfly',\n",
    "                   'caterpillar','cockroach','bear','leopard','lion','tiger','wolf','bridge','castle','house',\n",
    "                   'road','skyscraper','cloud','forest','mountain','plain','sea','camel','cattle','chimpanzee',\n",
    "                   'elephant','kangaroo','fox','porcupine','possum','raccoon','skunk','crab','lobster','snail',\n",
    "                   'spider','worm','baby','boy','girl','man','woman','crocodile','dinosaur','lizard','snake',\n",
    "                   'turtle','hamster','mouse','rabbit','shrew','squirrel','maple','oak','palm','pine','willow',\n",
    "                   'bicycle','bus','motorcycle','pickup truck','train','lawn-mower','rocket','streetcar','tank',\n",
    "                   'tractor']\n",
    "\n",
    "    class_distrib(y_train, labels_names, \"Training\")\n",
    "    class_distrib(y_val, labels_names, \"Validating\")\n",
    "    class_distrib(y_test, labels_names, \"Testing\")\n",
    "\n",
    "    # Create TensorFlow datasets\n",
    "\n",
    "    batch_size = 64\n",
    "\n",
    "    train_dataset = (tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "                     .map(lambda x, y: (tf.image.resize(x, (224, 224)),\n",
    "                                        tf.squeeze(tf.one_hot(y, depth=100, dtype=tf.float32))))  # Remove extra dimension\n",
    "                     .batch(batch_size)\n",
    "                     .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    val_dataset = (tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "                   .map(lambda x, y: (tf.image.resize(x, (224, 224)),\n",
    "                                      tf.squeeze(tf.one_hot(y, depth=100, dtype=tf.float32))))  # Remove extra dimension\n",
    "                   .batch(batch_size)\n",
    "                   .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    test_dataset = (tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "                     .map(lambda x, y: (tf.image.resize(x, (224, 224)),\n",
    "                                        tf.squeeze(tf.one_hot(y, depth=100, dtype=tf.float32))))  # Remove extra dimension\n",
    "                    .batch(batch_size)\n",
    "                    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    print(f\"Training dataset:\\n {train_dataset}\")\n",
    "    for img, lbl in train_dataset.take(1):\n",
    "        #if isinstance(batch, tuple) and len(batch) == 2:\n",
    "        print(f\"Image shape: {img.shape}\")  # Should be (batch_size, 224, 224, 3)\n",
    "        print(f\"Label shape: {lbl.shape}\")  # Should be (batch_size, 10)\n",
    "        del img,lbl\n",
    "    print(f\"\\nValidation dataset:\\n {val_dataset}\")\n",
    "    for img, lbl in val_dataset.take(1):\n",
    "        #if isinstance(batch, tuple) and len(batch) == 2:\n",
    "        print(f\"Image shape: {img.shape}\")  # Should be (batch_size, 224, 224, 3)\n",
    "        print(f\"Label shape: {lbl.shape}\")  # Should be (batch_size, 10)\n",
    "        del img,lbl\n",
    "    print(f\"\\nTesting dataset:\\n {test_dataset}\")\n",
    "    for img, lbl in test_dataset.take(1):\n",
    "        #if isinstance(batch, tuple) and len(batch) == 2:\n",
    "        print(f\"Image shape: {img.shape}\")  # Should be (batch_size, 224, 224, 3)\n",
    "        print(f\"Label shape: {lbl.shape}\")  # Should be (batch_size, 10)\n",
    "        del img,lbl\n",
    "\n",
    "\n",
    "    #### <<<<<<<<<<Pre-trained model>>>>>>>>>>\n",
    "    # Load ResNet50 pre-trained on ImageNet (w/out the top classification layer which is designed for ImageNet (diff dataset))\n",
    "    resnet_50_base = tf.keras.applications.ResNet50V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Freeze the layers of VGG16 so they don't get updated during training - can unfreeze for fine tuning later\n",
    "    resnet_50_base.trainable = False\n",
    "\n",
    "    # Add custom classification layers for CIFAR-100 (100 classes) - adapt model to CIFAR-100\n",
    "    model = models.Sequential([\n",
    "        resnet_50_base,\n",
    "        layers.GlobalAveragePooling2D(), # Better for ResNet than Flatten\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.6), # DEBUG dropout\n",
    "        layers.Dense(100, activation='softmax')  # CIFAR-100 has 100 classes\n",
    "    ])\n",
    "\n",
    "    for sample in test_dataset.take(1):\n",
    "        print(type(sample))  # Should be <class 'tuple'>\n",
    "        print(len(sample))  # Should be 2\n",
    "        print(type(sample[0]), type(sample[1]))  # Both should be <class 'tensorflow.Tensor'>\n",
    "        print(sample[0].shape)  # Should be (batch_size, 224, 224, 3)\n",
    "        print(sample[1].shape)  # Should be (batch_size, 100)\n",
    "    print(f\"Model input shape: {model.input_shape}\")\n",
    "    print(f\"Model output shape: {model.output_shape}\")\n",
    "    sample = next(iter(test_dataset.as_numpy_iterator()))\n",
    "    print(len(sample))  # Should be 2\n",
    "    print(type(sample[0]), type(sample[1]))  # Both should be <class 'numpy.ndarray'>\n",
    "    print(sample[0].shape, sample[1].shape)  # Should match model input and output\n",
    "    print(\"\\n\")\n",
    "    #for x, y in test_dataset.take(1):\n",
    "    #    print(type(x), type(y))  # Both should be <class 'tensorflow.Tensor'>\n",
    "    #for x_batch, y_batch in test_dataset.take(1):\n",
    "    #    test_loss, test_acc = model.evaluate(x_batch, y_batch)\n",
    "    #    print(f\"Test Loss: {test_loss}, Test Accuracy: {test_acc}\")\n",
    "\n",
    "    # Compile the model\n",
    "    #tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-3, weight_decay=3e-2), # DEBUG weight\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', 'precision', 'f1_score'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    #### <<<<<<<<<<Train Model & Track Training/Validation Error>>>>>>>>>>\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', # or val_accuracy\n",
    "                                   patience=5, # Num. epochs with no improvements - help void overfitting\n",
    "                                   restore_best_weights=True)\n",
    "    #reduce_lr = ReduceLROnPlateau(monitor='val_loss', # or val_accuracy\n",
    "    #                              factor=0.1, # Reduce lr by a factor\n",
    "    #                              patience=3, # Num epochs w/ no improvement\n",
    "    #                              min_lr=1e-6, # Min lr\n",
    "    #                              verbose=1)\n",
    "    #tensorboard = TensorBoard(log_dir='./logs', # Logs directory\n",
    "    #                         histogram_freq=1, # Logs histograms for weights/activations\n",
    "    #                         write_graph=True, # Logs graph of model\n",
    "    #                         write_images=True) # Log images like weight histogram\n",
    "    checkpoint = ModelCheckpoint('best_model_v1.keras', # Path where the best model will be saved\n",
    "                                 monitor='val_loss', # What to monitor (validation loss)\n",
    "                                 save_best_only=True, # Only save model when validation loss improves\n",
    "                                 mode='min', # Looking to minimse the validation loss\n",
    "                                 verbose=1) # Print out message when saving model\n",
    "    checkpoint_fine_tune = ModelCheckpoint('best_model_fine_tune_v1.keras', # Path where the best model will be saved\n",
    "                                 monitor='val_loss', # What to monitor (validation loss)\n",
    "                                 save_best_only=True, # Only save model when validation loss improves\n",
    "                                 mode='min', # Looking to minimse the validation loss\n",
    "                                 verbose=1) # Print out message when saving model\n",
    "    #cvs_logger = CSVLogger('training_log.csv', seperator=',', append=True) # Save train metrics to analyse\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_dataset, validation_data=val_dataset, epochs=25,\n",
    "                        batch_size=batch_size, callbacks=[early_stopping, checkpoint], verbose=1)\n",
    "\n",
    "    #### <<<<<<<<<<Plot Training & Validation Error>>>>>>>>>>\n",
    "\n",
    "    # Extract loss and accuracy\n",
    "    epochs = range(1,len(history.history['loss'])+1)\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    plot_evidence(epochs, train_loss, val_loss, train_acc, val_acc)\n",
    "\n",
    "    #### <<<<<<<<<<Evaluate Model on Test Data>>>>>>>>>>\n",
    "\n",
    "    # Evaluate on test data\n",
    "    model = load_model('best_model_v1.keras')\n",
    "    results = model.evaluate(test_dataset)\n",
    "    test_loss = results[0]\n",
    "    test_acc = results[1]\n",
    "    test_precision = results[2]\n",
    "    test_f1_scores = results[3]\n",
    "    print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print(f\"Test Precision: {test_precision*100:.2f}%\")\n",
    "    print(f\"Test F1 Scores (Per Class): {test_f1_scores.numpy()*100}\")\n",
    "    print(f\"Average Test F1 Scores:{np.average(test_f1_scores.numpy()*100):.2f}\\n\")\n",
    "\n",
    "    #### <<<<<<<<<<Generate Confusion Matrix>>>>>>>>>>\n",
    "\n",
    "    # Get predictions\n",
    "    X_test_revised = tf.image.resize(X_test, (224, 224))\n",
    "    y_pred = model.predict(X_test_revised)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = y_test.flatten()\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(conf_matrix) #cmap='Blues', fmt='d'\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_true_classes, y_pred_classes, target_names=labels_names))\n",
    "    #tensorboard --logdir==path_to_your_logs\n",
    "\n",
    "    # Create a DataFrame from the history of the training and store the epoch values.\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    # Finally, display the hist DataFrame.\n",
    "    hist\n",
    "\n",
    "    #### <<<<<<<<<<Fine-Tune>>>>>>>>>>\n",
    "    # Adapt Model\n",
    "    for layer in resnet_50_base.layers:\n",
    "        layer.trainable = True # Allow layers to be updated\n",
    "\n",
    "    # Compile again w/ lower learning rate (prevents destroying learned features)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-5),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', 'precision', 'f1_score'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    #### <<<<<<<<<<Modify Dataset>>>>>>>>>>\n",
    "\n",
    "\n",
    "    # DEBUG augment\n",
    "    train_dataset_aug_ = (tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "                     .map(augment_dataset, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                     .batch(batch_size)\n",
    "                     .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    # Combine the original dataset and the augmented dataset\n",
    "    train_dataset_aug = train_dataset.concatenate(train_dataset_aug_) # Not val or test as augment train helps generalise better, but want to provide consistent benchmark for eval perf\n",
    "\n",
    "    #### <<<<<<<<<<Train Model & Track Training/Validation Error>>>>>>>>>>\n",
    "\n",
    "    # Train the model\n",
    "    history_fine_tune = model.fit(train_dataset_aug, validation_data=val_dataset, epochs=15,\n",
    "                                  batch_size=batch_size, callbacks=[early_stopping, checkpoint_fine_tune], verbose=1)\n",
    "\n",
    "    #### <<<<<<<<<<Plot Training & Validation Error>>>>>>>>>>\n",
    "\n",
    "    # Extract loss and accuracy\n",
    "    epochs = range(1,len(history_fine_tune.history['loss'])+1)\n",
    "    train_loss = history_fine_tune.history['loss']\n",
    "    val_loss = history_fine_tune.history['val_loss']\n",
    "    train_acc = history_fine_tune.history['accuracy']\n",
    "    val_acc = history_fine_tune.history['val_accuracy']\n",
    "\n",
    "    plot_evidence(epochs, train_loss, val_loss, train_acc, val_acc)\n",
    "\n",
    "    #### <<<<<<<<<<Evaluate Model on Test Data>>>>>>>>>>\n",
    "\n",
    "    # Evaluate on test data\n",
    "    model_fine_tune = load_model('best_model_fine_tune_v1.keras')\n",
    "    results = model_fine_tune.evaluate(test_dataset)\n",
    "    test_loss = results[0]\n",
    "    test_acc = results[1]\n",
    "    test_precision = results[2]\n",
    "    test_f1_scores = results[3]\n",
    "    print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print(f\"Test Precision: {test_precision*100:.2f}%\")\n",
    "    print(f\"Test F1 Scores (Per Class): {test_f1_scores.numpy()*100}\")\n",
    "    print(f\"Average Test F1 Scores:{np.average(test_f1_scores.numpy()*100):.2f}\\n\")\n",
    "\n",
    "    #### <<<<<<<<<<Generate Confusion Matrix>>>>>>>>>>\n",
    "\n",
    "    # Get predictions\n",
    "    X_test_revised = tf.image.resize(X_test, (224, 224))\n",
    "    y_pred = model_fine_tune.predict(X_test_revised)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = y_test.flatten()\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(conf_matrix) #cmap='Blues', fmt='d'\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_true_classes, y_pred_classes, target_names=labels_names))\n",
    "\n",
    "    # Create a DataFrame from the history of the training and store the epoch values.\n",
    "    hist = pd.DataFrame(history_fine_tune.history)\n",
    "    hist['epoch'] = history_fine_tune.epoch\n",
    "\n",
    "    # Finally, display the hist DataFrame.\n",
    "    hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e76976-aaec-4598-8801-79b67e59c84c",
   "metadata": {
    "id": "f7e76976-aaec-4598-8801-79b67e59c84c"
   },
   "source": [
    "# Dropout(0.6), weight_decay(3e-2), l2(3e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84275d6-059b-4aa3-a823-2ab9c25c3e2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f84275d6-059b-4aa3-a823-2ab9c25c3e2b",
    "outputId": "1612f0b3-4b9f-4f0b-b67b-a7dcdd10aac7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for repeat_2_times in range(2):\n",
    "    #### <<<<<<<<<<Load and process data>>>>>>>>>>\n",
    "    # Load CIFAR-100 dataset\n",
    "    (X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "\n",
    "    # Split (8000) of training data into temporary set\n",
    "    X_temp, X_train, y_temp, y_train = train_test_split(X_train, y_train, test_size=0.84, stratify=y_train, random_state=42)\n",
    "    print(f\"X_temp.shape: {X_temp.shape}\\n\")\n",
    "\n",
    "    # Split temp data into equal validation (4000) and testing (4000) data\n",
    "    X_temp_val, X_temp_test, y_temp_val, y_temp_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "    print(f\"X_temp_val.shape: {X_temp_val.shape}\")\n",
    "    print(f\"y_temp_val.shape: {y_temp_val.shape}\")\n",
    "    print(f\"X_temp_test.shape: {X_temp_test.shape}\")\n",
    "    print(f\"y_temp_test.shape: {y_temp_test.shape}\\n\")\n",
    "\n",
    "    # Split test data into validation (5000) and testing (5000)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=42)\n",
    "\n",
    "    # Add temp_val to validation (9000) and temp_test to testing (9000) to get a 70/15/15 data split\n",
    "    X_val = np.concatenate((X_val, X_temp_val), axis=0)\n",
    "    y_val = np.concatenate((y_val, y_temp_val), axis=0)\n",
    "    X_test = np.concatenate((X_test, X_temp_test), axis=0)\n",
    "    y_test = np.concatenate((y_test, y_temp_test), axis=0)\n",
    "\n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"y_train.shape: {y_train.shape}\")\n",
    "    print(f\"X_val.shape: {X_val.shape}\")\n",
    "    print(f\"y_val.shape: {y_val.shape}\")\n",
    "    print(f\"X_test.shape: {X_test.shape}\")\n",
    "    print(f\"y_test.shape: {y_test.shape}\\n\")\n",
    "\n",
    "    display_imgs(X_train, y_train)\n",
    "\n",
    "    # Normalise images (scale to range [0, 1]) - Improves convergence speed & accuracy\n",
    "    X_train, X_val, X_test = X_train / 255.0, X_val / 255.0, X_test / 255.0\n",
    "    display_imgs(X_train, y_train)\n",
    "\n",
    "    labels_names = ['beaver','dolphin','otter','seal','whale','aquarium fish','flatfish','ray','shark','trout',\n",
    "                   'orchids','poppies','roses','sunflowers','tulips','bottles','bowls','cans','cups','plates',\n",
    "                   'apples','mushrooms','oranges','pears','sweet peppers','clock','computer keyboard','lamp',\n",
    "                   'telephone','television','bed','chair','couch','table','wardrobe','bee','beetle','butterfly',\n",
    "                   'caterpillar','cockroach','bear','leopard','lion','tiger','wolf','bridge','castle','house',\n",
    "                   'road','skyscraper','cloud','forest','mountain','plain','sea','camel','cattle','chimpanzee',\n",
    "                   'elephant','kangaroo','fox','porcupine','possum','raccoon','skunk','crab','lobster','snail',\n",
    "                   'spider','worm','baby','boy','girl','man','woman','crocodile','dinosaur','lizard','snake',\n",
    "                   'turtle','hamster','mouse','rabbit','shrew','squirrel','maple','oak','palm','pine','willow',\n",
    "                   'bicycle','bus','motorcycle','pickup truck','train','lawn-mower','rocket','streetcar','tank',\n",
    "                   'tractor']\n",
    "\n",
    "    class_distrib(y_train, labels_names, \"Training\")\n",
    "    class_distrib(y_val, labels_names, \"Validating\")\n",
    "    class_distrib(y_test, labels_names, \"Testing\")\n",
    "\n",
    "    # Create TensorFlow datasets\n",
    "\n",
    "    batch_size = 64\n",
    "\n",
    "    train_dataset_ = (tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "                     .map(lambda x, y: (tf.image.resize(x, (224, 224)),\n",
    "                                        tf.squeeze(tf.one_hot(y, depth=100, dtype=tf.float32))))  # Remove extra dimension\n",
    "                     .batch(batch_size)\n",
    "                     .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    # DEBUG augment\n",
    "    #train_dataset_aug = (tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    #                 .map(augment_dataset, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    #                 .batch(batch_size)\n",
    "    #                 .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    # Combine the original dataset and the augmented dataset\n",
    "    train_dataset = train_dataset_#.concatenate(train_dataset_aug)\n",
    "\n",
    "    val_dataset = (tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "                   .map(lambda x, y: (tf.image.resize(x, (224, 224)),\n",
    "                                      tf.squeeze(tf.one_hot(y, depth=100, dtype=tf.float32))))  # Remove extra dimension\n",
    "                   .batch(batch_size)\n",
    "                   .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    test_dataset = (tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "                     .map(lambda x, y: (tf.image.resize(x, (224, 224)),\n",
    "                                        tf.squeeze(tf.one_hot(y, depth=100, dtype=tf.float32))))  # Remove extra dimension\n",
    "                    .batch(batch_size)\n",
    "                    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    print(f\"Training dataset:\\n {train_dataset}\")\n",
    "    for img, lbl in train_dataset.take(1):\n",
    "        #if isinstance(batch, tuple) and len(batch) == 2:\n",
    "        print(f\"Image shape: {img.shape}\")  # Should be (batch_size, 224, 224, 3)\n",
    "        print(f\"Label shape: {lbl.shape}\")  # Should be (batch_size, 10)\n",
    "        del img,lbl\n",
    "    print(f\"\\nValidation dataset:\\n {val_dataset}\")\n",
    "    for img, lbl in val_dataset.take(1):\n",
    "        #if isinstance(batch, tuple) and len(batch) == 2:\n",
    "        print(f\"Image shape: {img.shape}\")  # Should be (batch_size, 224, 224, 3)\n",
    "        print(f\"Label shape: {lbl.shape}\")  # Should be (batch_size, 10)\n",
    "        del img,lbl\n",
    "    print(f\"\\nTesting dataset:\\n {test_dataset}\")\n",
    "    for img, lbl in test_dataset.take(1):\n",
    "        #if isinstance(batch, tuple) and len(batch) == 2:\n",
    "        print(f\"Image shape: {img.shape}\")  # Should be (batch_size, 224, 224, 3)\n",
    "        print(f\"Label shape: {lbl.shape}\")  # Should be (batch_size, 10)\n",
    "        del img,lbl\n",
    "\n",
    "\n",
    "    #### <<<<<<<<<<Pre-trained model>>>>>>>>>>\n",
    "    # Load ResNet50 pre-trained on ImageNet (w/out the top classification layer which is designed for ImageNet (diff dataset))\n",
    "    resnet_50_base = tf.keras.applications.ResNet50V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Freeze the layers of VGG16 so they don't get updated during training - can unfreeze for fine tuning later\n",
    "    resnet_50_base.trainable = False\n",
    "\n",
    "    for layer in resnet_50_base.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            layer.kernel_regularizer = tf.keras.regularizers.l2(3e-2) # DEBUG l2\n",
    "\n",
    "    # Add custom classification layers for CIFAR-100 (100 classes) - adapt model to CIFAR-100\n",
    "    model = models.Sequential([\n",
    "        resnet_50_base,\n",
    "        layers.GlobalAveragePooling2D(), # Better for ResNet than Flatten\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.6), # DEBUG dropout\n",
    "        layers.Dense(100, activation='softmax')  # CIFAR-100 has 100 classes\n",
    "    ])\n",
    "\n",
    "    for sample in test_dataset.take(1):\n",
    "        print(type(sample))  # Should be <class 'tuple'>\n",
    "        print(len(sample))  # Should be 2\n",
    "        print(type(sample[0]), type(sample[1]))  # Both should be <class 'tensorflow.Tensor'>\n",
    "        print(sample[0].shape)  # Should be (batch_size, 224, 224, 3)\n",
    "        print(sample[1].shape)  # Should be (batch_size, 100)\n",
    "    print(f\"Model input shape: {model.input_shape}\")\n",
    "    print(f\"Model output shape: {model.output_shape}\")\n",
    "    sample = next(iter(test_dataset.as_numpy_iterator()))\n",
    "    print(len(sample))  # Should be 2\n",
    "    print(type(sample[0]), type(sample[1]))  # Both should be <class 'numpy.ndarray'>\n",
    "    print(sample[0].shape, sample[1].shape)  # Should match model input and output\n",
    "    print(\"\\n\")\n",
    "    #for x, y in test_dataset.take(1):\n",
    "    #    print(type(x), type(y))  # Both should be <class 'tensorflow.Tensor'>\n",
    "    #for x_batch, y_batch in test_dataset.take(1):\n",
    "    #    test_loss, test_acc = model.evaluate(x_batch, y_batch)\n",
    "    #    print(f\"Test Loss: {test_loss}, Test Accuracy: {test_acc}\")\n",
    "\n",
    "    # Compile the model\n",
    "    #tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-3, weight_decay=3e-2), # DEBUG weight\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', 'precision', 'f1_score'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    #### <<<<<<<<<<Train Model & Track Training/Validation Error>>>>>>>>>>\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', # or val_accuracy\n",
    "                                   patience=5, # Num. epochs with no improvements - help void overfitting\n",
    "                                   restore_best_weights=True)\n",
    "    #reduce_lr = ReduceLROnPlateau(monitor='val_loss', # or val_accuracy\n",
    "    #                              factor=0.1, # Reduce lr by a factor\n",
    "    #                              patience=3, # Num epochs w/ no improvement\n",
    "    #                              min_lr=1e-6, # Min lr\n",
    "    #                              verbose=1)\n",
    "    #tensorboard = TensorBoard(log_dir='./logs', # Logs directory\n",
    "    #                         histogram_freq=1, # Logs histograms for weights/activations\n",
    "    #                         write_graph=True, # Logs graph of model\n",
    "    #                         write_images=True) # Log images like weight histogram\n",
    "    checkpoint = ModelCheckpoint('best_model_v2.keras', # Path where the best model will be saved\n",
    "                                 monitor='val_loss', # What to monitor (validation loss)\n",
    "                                 save_best_only=True, # Only save model when validation loss improves\n",
    "                                 mode='min', # Looking to minimse the validation loss\n",
    "                                 verbose=1) # Print out message when saving model\n",
    "    checkpoint_fine_tune = ModelCheckpoint('best_model_fine_tune_v2.keras', # Path where the best model will be saved\n",
    "                                 monitor='val_loss', # What to monitor (validation loss)\n",
    "                                 save_best_only=True, # Only save model when validation loss improves\n",
    "                                 mode='min', # Looking to minimse the validation loss\n",
    "                                 verbose=1) # Print out message when saving model\n",
    "    #cvs_logger = CSVLogger('training_log.csv', seperator=',', append=True) # Save train metrics to analyse\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_dataset, validation_data=val_dataset, epochs=25,\n",
    "                        batch_size=batch_size, callbacks=[early_stopping, checkpoint], verbose=1)\n",
    "\n",
    "    #### <<<<<<<<<<Plot Training & Validation Error>>>>>>>>>>\n",
    "\n",
    "    # Extract loss and accuracy\n",
    "    epochs = range(1,len(history.history['loss'])+1)\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    plot_evidence(epochs, train_loss, val_loss, train_acc, val_acc)\n",
    "\n",
    "    #### <<<<<<<<<<Evaluate Model on Test Data>>>>>>>>>>\n",
    "\n",
    "    # Evaluate on test data\n",
    "    model = load_model('best_model_v2.keras')\n",
    "    results = model.evaluate(test_dataset)\n",
    "    test_loss = results[0]\n",
    "    test_acc = results[1]\n",
    "    test_precision = results[2]\n",
    "    test_f1_scores = results[3]\n",
    "    print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print(f\"Test Precision: {test_precision*100:.2f}%\")\n",
    "    print(f\"Test F1 Scores (Per Class): {test_f1_scores.numpy()*100}\")\n",
    "    print(f\"Average Test F1 Scores:{np.average(test_f1_scores.numpy()*100):.2f}\\n\")\n",
    "\n",
    "    #### <<<<<<<<<<Generate Confusion Matrix>>>>>>>>>>\n",
    "\n",
    "    # Get predictions\n",
    "    X_test_revised = tf.image.resize(X_test, (224, 224))\n",
    "    y_pred = model.predict(X_test_revised)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = y_test.flatten()\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(conf_matrix) #cmap='Blues', fmt='d'\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_true_classes, y_pred_classes, target_names=labels_names))\n",
    "    #tensorboard --logdir==path_to_your_logs\n",
    "\n",
    "    # Create a DataFrame from the history of the training and store the epoch values.\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    # Finally, display the hist DataFrame.\n",
    "    hist\n",
    "\n",
    "    #### <<<<<<<<<<Fine-Tune>>>>>>>>>>\n",
    "    # Adapt Model\n",
    "    for layer in resnet_50_base.layers:\n",
    "        layer.trainable = True # Allow layers to be updated\n",
    "\n",
    "    # Compile again w/ lower learning rate (prevents destroying learned features)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-5),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', 'precision', 'f1_score'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    #### <<<<<<<<<<Modify Dataset>>>>>>>>>>\n",
    "\n",
    "\n",
    "    # DEBUG augment\n",
    "    train_dataset_aug_ = (tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "                     .map(augment_dataset, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                     .batch(batch_size)\n",
    "                     .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    # Combine the original dataset and the augmented dataset\n",
    "    train_dataset_aug = train_dataset.concatenate(train_dataset_aug_) # Not val or test as augment train helps generalise better, but want to provide consistent benchmark for eval perf\n",
    "\n",
    "    #### <<<<<<<<<<Train Model & Track Training/Validation Error>>>>>>>>>>\n",
    "\n",
    "    # Train the model\n",
    "    history_fine_tune = model.fit(train_dataset_aug, validation_data=val_dataset, epochs=15,\n",
    "                                  batch_size=batch_size, callbacks=[early_stopping, checkpoint_fine_tune], verbose=1)\n",
    "\n",
    "    #### <<<<<<<<<<Plot Training & Validation Error>>>>>>>>>>\n",
    "\n",
    "    # Extract loss and accuracy\n",
    "    epochs = range(1,len(history_fine_tune.history['loss'])+1)\n",
    "    train_loss = history_fine_tune.history['loss']\n",
    "    val_loss = history_fine_tune.history['val_loss']\n",
    "    train_acc = history_fine_tune.history['accuracy']\n",
    "    val_acc = history_fine_tune.history['val_accuracy']\n",
    "\n",
    "    plot_evidence(epochs, train_loss, val_loss, train_acc, val_acc)\n",
    "\n",
    "    #### <<<<<<<<<<Evaluate Model on Test Data>>>>>>>>>>\n",
    "\n",
    "    # Evaluate on test data\n",
    "    model_fine_tune = load_model('best_model_fine_tune_v2.keras')\n",
    "    results = model_fine_tune.evaluate(test_dataset)\n",
    "    test_loss = results[0]\n",
    "    test_acc = results[1]\n",
    "    test_precision = results[2]\n",
    "    test_f1_scores = results[3]\n",
    "    print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print(f\"Test Precision: {test_precision*100:.2f}%\")\n",
    "    print(f\"Test F1 Scores (Per Class): {test_f1_scores.numpy()*100}\")\n",
    "    print(f\"Average Test F1 Scores:{np.average(test_f1_scores.numpy()*100):.2f}\\n\")\n",
    "\n",
    "    #### <<<<<<<<<<Generate Confusion Matrix>>>>>>>>>>\n",
    "\n",
    "    # Get predictions\n",
    "    X_test_revised = tf.image.resize(X_test, (224, 224))\n",
    "    y_pred = model_fine_tune.predict(X_test_revised)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = y_test.flatten()\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(conf_matrix) #cmap='Blues', fmt='d'\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_true_classes, y_pred_classes, target_names=labels_names))\n",
    "\n",
    "    # Create a DataFrame from the history of the training and store the epoch values.\n",
    "    hist = pd.DataFrame(history_fine_tune.history)\n",
    "    hist['epoch'] = history_fine_tune.epoch\n",
    "\n",
    "    # Finally, display the hist DataFrame.\n",
    "    hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1121697-2889-4556-a7de-02dc61cbc5c1",
   "metadata": {
    "id": "b1121697-2889-4556-a7de-02dc61cbc5c1"
   },
   "source": [
    "# Dropout(0.6), L2Reg(3e-2), weight_decay(3e-2), train_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ba23c-caed-48c2-9eb7-bdd69be8096c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "025ba23c-caed-48c2-9eb7-bdd69be8096c",
    "outputId": "36d39204-e031-4337-b138-bcd2393b6516",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for repeat_2_times in range(2):\n",
    "    #### <<<<<<<<<<Load and process data>>>>>>>>>>\n",
    "    # Load CIFAR-100 dataset\n",
    "    (X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "\n",
    "    # Split (8000) of training data into temporary set\n",
    "    X_temp, X_train, y_temp, y_train = train_test_split(X_train, y_train, test_size=0.84, stratify=y_train, random_state=42)\n",
    "    print(f\"X_temp.shape: {X_temp.shape}\\n\")\n",
    "\n",
    "    # Split temp data into equal validation (4000) and testing (4000) data\n",
    "    X_temp_val, X_temp_test, y_temp_val, y_temp_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "    print(f\"X_temp_val.shape: {X_temp_val.shape}\")\n",
    "    print(f\"y_temp_val.shape: {y_temp_val.shape}\")\n",
    "    print(f\"X_temp_test.shape: {X_temp_test.shape}\")\n",
    "    print(f\"y_temp_test.shape: {y_temp_test.shape}\\n\")\n",
    "\n",
    "    # Split test data into validation (5000) and testing (5000)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=42)\n",
    "\n",
    "    # Add temp_val to validation (9000) and temp_test to testing (9000) to get a 70/15/15 data split\n",
    "    X_val = np.concatenate((X_val, X_temp_val), axis=0)\n",
    "    y_val = np.concatenate((y_val, y_temp_val), axis=0)\n",
    "    X_test = np.concatenate((X_test, X_temp_test), axis=0)\n",
    "    y_test = np.concatenate((y_test, y_temp_test), axis=0)\n",
    "\n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"y_train.shape: {y_train.shape}\")\n",
    "    print(f\"X_val.shape: {X_val.shape}\")\n",
    "    print(f\"y_val.shape: {y_val.shape}\")\n",
    "    print(f\"X_test.shape: {X_test.shape}\")\n",
    "    print(f\"y_test.shape: {y_test.shape}\\n\")\n",
    "\n",
    "    display_imgs(X_train, y_train)\n",
    "\n",
    "    # Normalise images (scale to range [0, 1]) - Improves convergence speed & accuracy\n",
    "    X_train, X_val, X_test = X_train / 255.0, X_val / 255.0, X_test / 255.0\n",
    "    display_imgs(X_train, y_train)\n",
    "\n",
    "    labels_names = ['beaver','dolphin','otter','seal','whale','aquarium fish','flatfish','ray','shark','trout',\n",
    "                   'orchids','poppies','roses','sunflowers','tulips','bottles','bowls','cans','cups','plates',\n",
    "                   'apples','mushrooms','oranges','pears','sweet peppers','clock','computer keyboard','lamp',\n",
    "                   'telephone','television','bed','chair','couch','table','wardrobe','bee','beetle','butterfly',\n",
    "                   'caterpillar','cockroach','bear','leopard','lion','tiger','wolf','bridge','castle','house',\n",
    "                   'road','skyscraper','cloud','forest','mountain','plain','sea','camel','cattle','chimpanzee',\n",
    "                   'elephant','kangaroo','fox','porcupine','possum','raccoon','skunk','crab','lobster','snail',\n",
    "                   'spider','worm','baby','boy','girl','man','woman','crocodile','dinosaur','lizard','snake',\n",
    "                   'turtle','hamster','mouse','rabbit','shrew','squirrel','maple','oak','palm','pine','willow',\n",
    "                   'bicycle','bus','motorcycle','pickup truck','train','lawn-mower','rocket','streetcar','tank',\n",
    "                   'tractor']\n",
    "\n",
    "    class_distrib(y_train, labels_names, \"Training\")\n",
    "    class_distrib(y_val, labels_names, \"Validating\")\n",
    "    class_distrib(y_test, labels_names, \"Testing\")\n",
    "\n",
    "    # Create TensorFlow datasets\n",
    "\n",
    "    batch_size = 64\n",
    "\n",
    "    train_dataset_ = (tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "                     .map(lambda x, y: (tf.image.resize(x, (224, 224)),\n",
    "                                        tf.squeeze(tf.one_hot(y, depth=100, dtype=tf.float32))))  # Remove extra dimension\n",
    "                     .batch(batch_size)\n",
    "                     .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    # DEBUG augment\n",
    "    #train_dataset_aug = (tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    #                 .map(augment_dataset, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    #                 .batch(batch_size)\n",
    "    #                 .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    # Combine the original dataset and the augmented dataset\n",
    "    train_dataset = train_dataset_#.concatenate(train_dataset_aug)\n",
    "\n",
    "    val_dataset = (tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "                   .map(lambda x, y: (tf.image.resize(x, (224, 224)),\n",
    "                                      tf.squeeze(tf.one_hot(y, depth=100, dtype=tf.float32))))  # Remove extra dimension\n",
    "                   .batch(batch_size)\n",
    "                   .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    test_dataset = (tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "                     .map(lambda x, y: (tf.image.resize(x, (224, 224)),\n",
    "                                        tf.squeeze(tf.one_hot(y, depth=100, dtype=tf.float32))))  # Remove extra dimension\n",
    "                    .batch(batch_size)\n",
    "                    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    print(f\"Training dataset:\\n {train_dataset}\")\n",
    "    for img, lbl in train_dataset.take(1):\n",
    "        #if isinstance(batch, tuple) and len(batch) == 2:\n",
    "        print(f\"Image shape: {img.shape}\")  # Should be (batch_size, 224, 224, 3)\n",
    "        print(f\"Label shape: {lbl.shape}\")  # Should be (batch_size, 10)\n",
    "        del img,lbl\n",
    "    print(f\"\\nValidation dataset:\\n {val_dataset}\")\n",
    "    for img, lbl in val_dataset.take(1):\n",
    "        #if isinstance(batch, tuple) and len(batch) == 2:\n",
    "        print(f\"Image shape: {img.shape}\")  # Should be (batch_size, 224, 224, 3)\n",
    "        print(f\"Label shape: {lbl.shape}\")  # Should be (batch_size, 10)\n",
    "        del img,lbl\n",
    "    print(f\"\\nTesting dataset:\\n {test_dataset}\")\n",
    "    for img, lbl in test_dataset.take(1):\n",
    "        #if isinstance(batch, tuple) and len(batch) == 2:\n",
    "        print(f\"Image shape: {img.shape}\")  # Should be (batch_size, 224, 224, 3)\n",
    "        print(f\"Label shape: {lbl.shape}\")  # Should be (batch_size, 10)\n",
    "        del img,lbl\n",
    "\n",
    "\n",
    "    #### <<<<<<<<<<Pre-trained model>>>>>>>>>>\n",
    "    # Load ResNet50 pre-trained on ImageNet (w/out the top classification layer which is designed for ImageNet (diff dataset))\n",
    "    resnet_50_base = tf.keras.applications.ResNet50V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Freeze the layers of VGG16 so they don't get updated during training - can unfreeze for fine tuning later\n",
    "    resnet_50_base.trainable = False\n",
    "\n",
    "    for layer in resnet_50_base.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            layer.kernel_regularizer = tf.keras.regularizers.l2(3e-2) # DEBUG l2\n",
    "\n",
    "    # Add custom classification layers for CIFAR-100 (100 classes) - adapt model to CIFAR-100\n",
    "    model = models.Sequential([\n",
    "        resnet_50_base,\n",
    "        layers.GlobalAveragePooling2D(), # Better for ResNet than Flatten\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.6), # DEBUG dropout\n",
    "        layers.Dense(100, activation='softmax')  # CIFAR-100 has 100 classes\n",
    "    ])\n",
    "\n",
    "    for sample in test_dataset.take(1):\n",
    "        print(type(sample))  # Should be <class 'tuple'>\n",
    "        print(len(sample))  # Should be 2\n",
    "        print(type(sample[0]), type(sample[1]))  # Both should be <class 'tensorflow.Tensor'>\n",
    "        print(sample[0].shape)  # Should be (batch_size, 224, 224, 3)\n",
    "        print(sample[1].shape)  # Should be (batch_size, 100)\n",
    "    print(f\"Model input shape: {model.input_shape}\")\n",
    "    print(f\"Model output shape: {model.output_shape}\")\n",
    "    sample = next(iter(test_dataset.as_numpy_iterator()))\n",
    "    print(len(sample))  # Should be 2\n",
    "    print(type(sample[0]), type(sample[1]))  # Both should be <class 'numpy.ndarray'>\n",
    "    print(sample[0].shape, sample[1].shape)  # Should match model input and output\n",
    "    print(\"\\n\")\n",
    "    #for x, y in test_dataset.take(1):\n",
    "    #    print(type(x), type(y))  # Both should be <class 'tensorflow.Tensor'>\n",
    "    #for x_batch, y_batch in test_dataset.take(1):\n",
    "    #    test_loss, test_acc = model.evaluate(x_batch, y_batch)\n",
    "    #    print(f\"Test Loss: {test_loss}, Test Accuracy: {test_acc}\")\n",
    "\n",
    "    # Compile the model\n",
    "    #tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-3, weight_decay=3e-2), # DEBUG weight\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', 'precision', 'f1_score'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    #### <<<<<<<<<<Train Model & Track Training/Validation Error>>>>>>>>>>\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', # or val_accuracy\n",
    "                                   patience=5, # Num. epochs with no improvements - help void overfitting\n",
    "                                   restore_best_weights=True)\n",
    "    #reduce_lr = ReduceLROnPlateau(monitor='val_loss', # or val_accuracy\n",
    "    #                              factor=0.1, # Reduce lr by a factor\n",
    "    #                              patience=3, # Num epochs w/ no improvement\n",
    "    #                              min_lr=1e-6, # Min lr\n",
    "    #                              verbose=1)\n",
    "    #tensorboard = TensorBoard(log_dir='./logs', # Logs directory\n",
    "    #                         histogram_freq=1, # Logs histograms for weights/activations\n",
    "    #                         write_graph=True, # Logs graph of model\n",
    "    #                         write_images=True) # Log images like weight histogram\n",
    "    checkpoint = ModelCheckpoint('best_model_v3.keras', # Path where the best model will be saved\n",
    "                                 monitor='val_loss', # What to monitor (validation loss)\n",
    "                                 save_best_only=True, # Only save model when validation loss improves\n",
    "                                 mode='min', # Looking to minimse the validation loss\n",
    "                                 verbose=1) # Print out message when saving model\n",
    "    checkpoint_fine_tune = ModelCheckpoint('best_model_fine_tune_v3.keras', # Path where the best model will be saved\n",
    "                                 monitor='val_loss', # What to monitor (validation loss)\n",
    "                                 save_best_only=True, # Only save model when validation loss improves\n",
    "                                 mode='min', # Looking to minimse the validation loss\n",
    "                                 verbose=1) # Print out message when saving model\n",
    "    #cvs_logger = CSVLogger('training_log.csv', seperator=',', append=True) # Save train metrics to analyse\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_dataset, validation_data=val_dataset, epochs=25,\n",
    "                        batch_size=batch_size, callbacks=[early_stopping, checkpoint], verbose=1)\n",
    "\n",
    "    #### <<<<<<<<<<Plot Training & Validation Error>>>>>>>>>>\n",
    "\n",
    "    # Extract loss and accuracy\n",
    "    epochs = range(1,len(history.history['loss'])+1)\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    plot_evidence(epochs, train_loss, val_loss, train_acc, val_acc)\n",
    "\n",
    "    #### <<<<<<<<<<Evaluate Model on Test Data>>>>>>>>>>\n",
    "\n",
    "    # Evaluate on test data\n",
    "    model = load_model('best_model_v3.keras')\n",
    "    results = model.evaluate(test_dataset)\n",
    "    test_loss = results[0]\n",
    "    test_acc = results[1]\n",
    "    test_precision = results[2]\n",
    "    test_f1_scores = results[3]\n",
    "    print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print(f\"Test Precision: {test_precision*100:.2f}%\")\n",
    "    print(f\"Test F1 Scores (Per Class): {test_f1_scores.numpy()*100}\")\n",
    "    print(f\"Average Test F1 Scores:{np.average(test_f1_scores.numpy()*100):.2f}\\n\")\n",
    "\n",
    "    #### <<<<<<<<<<Generate Confusion Matrix>>>>>>>>>>\n",
    "\n",
    "    # Get predictions\n",
    "    X_test_revised = tf.image.resize(X_test, (224, 224))\n",
    "    y_pred = model.predict(X_test_revised)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = y_test.flatten()\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(conf_matrix) #cmap='Blues', fmt='d'\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_true_classes, y_pred_classes, target_names=labels_names))\n",
    "    #tensorboard --logdir==path_to_your_logs\n",
    "\n",
    "    # Create a DataFrame from the history of the training and store the epoch values.\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    # Finally, display the hist DataFrame.\n",
    "    hist\n",
    "\n",
    "    #### <<<<<<<<<<Fine-Tune>>>>>>>>>>\n",
    "    # Adapt Model\n",
    "    for layer in resnet_50_base.layers:\n",
    "        layer.trainable = True # Allow layers to be updated\n",
    "\n",
    "    # Compile again w/ lower learning rate (prevents destroying learned features)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-5),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', 'precision', 'f1_score'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    #### <<<<<<<<<<Modify Dataset>>>>>>>>>>\n",
    "\n",
    "\n",
    "    # DEBUG augment\n",
    "    train_dataset_aug_ = (tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "                     .map(augment_dataset, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                     .batch(batch_size)\n",
    "                     .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    # Combine the original dataset and the augmented dataset\n",
    "    train_dataset_aug = train_dataset.concatenate(train_dataset_aug_) # Not val or test as augment train helps generalise better, but want to provide consistent benchmark for eval perf\n",
    "\n",
    "    #### <<<<<<<<<<Train Model & Track Training/Validation Error>>>>>>>>>>\n",
    "\n",
    "    # Train the model\n",
    "    history_fine_tune = model.fit(train_dataset_aug, validation_data=val_dataset, epochs=15,\n",
    "                                  batch_size=batch_size, callbacks=[early_stopping, checkpoint_fine_tune], verbose=1)\n",
    "\n",
    "    #### <<<<<<<<<<Plot Training & Validation Error>>>>>>>>>>\n",
    "\n",
    "    # Extract loss and accuracy\n",
    "    epochs = range(1,len(history_fine_tune.history['loss'])+1)\n",
    "    train_loss = history_fine_tune.history['loss']\n",
    "    val_loss = history_fine_tune.history['val_loss']\n",
    "    train_acc = history_fine_tune.history['accuracy']\n",
    "    val_acc = history_fine_tune.history['val_accuracy']\n",
    "\n",
    "    plot_evidence(epochs, train_loss, val_loss, train_acc, val_acc)\n",
    "\n",
    "    #### <<<<<<<<<<Evaluate Model on Test Data>>>>>>>>>>\n",
    "\n",
    "    # Evaluate on test data\n",
    "    model_fine_tune = load_model('best_model_fine_tune_v3.keras')\n",
    "    results = model_fine_tune.evaluate(test_dataset)\n",
    "    test_loss = results[0]\n",
    "    test_acc = results[1]\n",
    "    test_precision = results[2]\n",
    "    test_f1_scores = results[3]\n",
    "    print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print(f\"Test Precision: {test_precision*100:.2f}%\")\n",
    "    print(f\"Test F1 Scores (Per Class): {test_f1_scores.numpy()*100}\")\n",
    "    print(f\"Average Test F1 Scores:{np.average(test_f1_scores.numpy()*100):.2f}\\n\")\n",
    "\n",
    "    #### <<<<<<<<<<Generate Confusion Matrix>>>>>>>>>>\n",
    "\n",
    "    # Get predictions\n",
    "    X_test_revised = tf.image.resize(X_test, (224, 224))\n",
    "    y_pred = model_fine_tune.predict(X_test_revised)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = y_test.flatten()\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(conf_matrix) #cmap='Blues', fmt='d'\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_true_classes, y_pred_classes, target_names=labels_names))\n",
    "\n",
    "    # Create a DataFrame from the history of the training and store the epoch values.\n",
    "    hist = pd.DataFrame(history_fine_tune.history)\n",
    "    hist['epoch'] = history_fine_tune.epoch\n",
    "\n",
    "    # Finally, display the hist DataFrame.\n",
    "    hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c768b2c-1005-4d8e-876e-0c277e9fd6a0",
   "metadata": {
    "id": "5c768b2c-1005-4d8e-876e-0c277e9fd6a0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
